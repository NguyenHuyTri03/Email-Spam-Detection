{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import zipfile\n",
    "import csv\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from math import exp, log\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Set, Tuple, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip dataset\n",
    "with zipfile.ZipFile(\"data/dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(TypedDict):\n",
    "    text: str\n",
    "    spam: bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages: List[Message] = []\n",
    "msgs: List[str] = []\n",
    "spams: List[int] = []\n",
    "\n",
    "def transform(dict_, typed_dict) -> dict:\n",
    "    fields = typed_dict.__annotations__\n",
    "\n",
    "    for name, value in dict_.items():\n",
    "        if name == \"text\":\n",
    "            if value == \"\":\n",
    "                pass\n",
    "            else:\n",
    "                msgs.append(value.lstrip())\n",
    "                \n",
    "        elif name == \"spam\":\n",
    "            if value == \"\":\n",
    "                pass\n",
    "            else:\n",
    "                spams.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset and clean the dataset\n",
    "data = \"data/emails.csv\"\n",
    "\n",
    "with open(data, encoding=\"utf8\", newline='') as file:\n",
    "    for i, row in enumerate(csv.DictReader(file), 1):\n",
    "        transform(row, Message)\n",
    "\n",
    "    messages = list(zip(msgs, spams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input string and extract words with length >= 2\n",
    "def tokenize(text: str) -> Set[str]:\n",
    "    words: List[str] = []\n",
    "    for word in re.findall(r'[A-Za-z0-9\\']+', text):\n",
    "        if len(word) >= 3:\n",
    "            words.append(word.lower())\n",
    "    return set(words)\n",
    "\n",
    "assert tokenize('Is this a text? If so, Tokenize this text!...') == {'this', 'text', 'tokenize'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlit dataset into train and test sets (80/20)\n",
    "def train_test_split(messages: List[Message], pct=0.8) -> Tuple[List[Message], List[Message]]:\n",
    "    shuffle(messages)\n",
    "    num_train = int(round(len(messages) * pct, 0))\n",
    "    return messages[:num_train], messages[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self) -> None:\n",
    "        # `k` is the smoothening factor\n",
    "        self._k: int = 1\n",
    "        self._num_spam_messages: int = 0\n",
    "        self._num_ham_messages: int = 0\n",
    "        self._num_word_in_spam: Dict[int] = defaultdict(int)\n",
    "        self._num_word_in_ham: Dict[int] = defaultdict(int)\n",
    "        self._spam_words: Set[str] = set()\n",
    "        self._ham_words: Set[str] = set()\n",
    "        self._words: Set[str] = set()\n",
    "\n",
    "    # Iterate through the given messages and gather the necessary statistics\n",
    "    def train(self, messages: List[Message]) -> None:\n",
    "        msg: Message\n",
    "        token: str\n",
    "        for msg in messages:\n",
    "            tokens: Set[str] = tokenize(msg[0])\n",
    "            self._words.update(tokens)\n",
    "            if msg[1] == '1':\n",
    "                self._num_spam_messages += 1\n",
    "                self._spam_words.update(tokens)\n",
    "                for token in tokens:\n",
    "                    self._num_word_in_spam[token] += 1\n",
    "            else:\n",
    "                self._num_ham_messages += 1\n",
    "                self._ham_words.update(tokens)\n",
    "                for token in tokens:\n",
    "                    self._num_word_in_ham[token] += 1                \n",
    "    \n",
    "    # Probability of a word being spam\n",
    "    def word_spam_percent(self, word: str) -> float:\n",
    "        return (self._k + self._num_word_in_spam[word]) / ((2 * self._k) + self._num_spam_messages)\n",
    "    \n",
    "    # Probability of a word being ham\n",
    "    def word_ham_percent(self, word: str) -> float:\n",
    "        return (self._k + self._num_word_in_ham[word]) / ((2 * self._k) + self._num_ham_messages)\n",
    "    \n",
    "    # predict a word if it's spam\n",
    "    def predict(self, text: str) -> float:\n",
    "        text_words: Set[str] = tokenize(text)\n",
    "        log_p_spam: float = 0.0\n",
    "        log_p_ham: float = 0.0\n",
    "\n",
    "        for word in self._words:\n",
    "            p_spam: float = self.word_spam_percent(word)\n",
    "            p_ham: float = self.word_ham_percent(word)\n",
    "            if word in text_words:\n",
    "                log_p_spam += log(p_spam)\n",
    "                log_p_ham += log(p_ham)\n",
    "            else:\n",
    "                log_p_spam += log(1 - p_spam)\n",
    "                log_p_ham += log(1 - p_ham)\n",
    "\n",
    "        if_spam: float = exp(log_p_spam)\n",
    "        if_ham: float = exp(log_p_ham)\n",
    "        sum = if_spam + if_ham\n",
    "        if sum == 0:\n",
    "            sum = 0.1\n",
    "\n",
    "        return round(if_spam / sum, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581 1145\n"
     ]
    }
   ],
   "source": [
    "train: List[Message]\n",
    "test: List[Message]\n",
    "\n",
    "train, test = train_test_split(messages)\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam messages in training data: 1107\n",
      "Ham messages in training data: 3474\n",
      "Most spam words: [('subject', 1107), ('the', 869), ('and', 803), ('you', 793), ('your', 775), ('for', 731), ('this', 540), ('with', 520), ('have', 509), ('our', 498), ('not', 495), ('are', 479), ('from', 468), ('here', 428), ('that', 422), ('will', 387), ('all', 382), ('com', 357), ('more', 329), ('now', 308)]\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes()\n",
    "nb.train(train)\n",
    "\n",
    "print(f'Spam messages in training data: {nb._num_spam_messages}')\n",
    "print(f'Ham messages in training data: {nb._num_ham_messages}')\n",
    "print(f'Most spam words: {Counter(nb._num_word_in_spam).most_common(20)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 0.999052\n",
      "Probability: 1e-06\n",
      "Probability: 0.894392\n"
     ]
    }
   ],
   "source": [
    "# Manual test\n",
    "# spam: 1, 3\n",
    "emails = [\n",
    "    \"Hey, Jill!\\nIt's great to have you as part of our 8 Ball Pool family!\\nHere's a quick tip we hope you'll find useful:\\nPlay using Facebook login & reap rewards like...\\n5 FREE Pool Cash at time of login\\nFree Coins every hour\\nPlay on multiple devices\\nPlay with and challenge your friends\\nFree Gifts\\nHere's a little gift to help you along your 8 Ball Pool journey. Click the button below to collect now!\",\n",
    "    \"It was nice meeting you earlier. It would be great to be able to see you again.\",\n",
    "    \"Hello\\nAre you tired? Are you exhausted after a long day at work? Signup to receive a free spa at testurl.com\"\n",
    "]\n",
    "\n",
    "for email in emails:\n",
    "    print(f\"Probability: {nb.predict(email)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam count: 261\n",
      "spam predicted: 218\n",
      "Accuracy of spam prediction: 82.49105938697319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict messages from test set\n",
    "spam_prob: float = 0.0\n",
    "spam_count: int = 0\n",
    "spam_predict_count: int = 0\n",
    "\n",
    "for msg in test:\n",
    "    prob: float = nb.predict(msg[0])\n",
    "\n",
    "    # Count spam messages\n",
    "    if(msg[1] == \"1\"):\n",
    "        spam_count += 1\n",
    "\n",
    "    # Return the prediction of all the test message\n",
    "\n",
    "    if(prob >= 0.4):\n",
    "        spam_prob += prob\n",
    "        spam_predict_count += 1\n",
    "\n",
    "print(f\"spam count: {spam_count}\")\n",
    "print(f\"spam predicted: {spam_predict_count}\")\n",
    "print(f\"Accuracy of spam prediction: {(spam_prob / spam_count) * 100}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
