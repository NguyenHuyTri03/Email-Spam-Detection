{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import zipfile\n",
    "import csv\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from math import exp, log\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Set, Tuple, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip dataset\n",
    "with zipfile.ZipFile(\"data\\\\dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(TypedDict):\n",
    "    text: str\n",
    "    spam: bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages: List[Message] = []\n",
    "msgs: List[str] = []\n",
    "spams: List[int] = []\n",
    "\n",
    "# Take data input from csv and format them to Message class\n",
    "def transform(dict_, typed_dict) -> dict:\n",
    "    fields = typed_dict.__annotations__\n",
    "\n",
    "    for name, value in dict_.items():\n",
    "        if name == \"text\":\n",
    "            if value == \"\":\n",
    "                pass\n",
    "            else:\n",
    "                msgs.append(value.lstrip())\n",
    "                \n",
    "        elif name == \"spam\":\n",
    "            if value == \"\":\n",
    "                pass\n",
    "            else:\n",
    "                spams.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "data = \"data/emails.csv\"\n",
    "\n",
    "with open(data, encoding=\"utf8\", newline='') as file:\n",
    "    for i, row in enumerate(csv.DictReader(file), 1):\n",
    "        transform(row, Message)\n",
    "\n",
    "    messages = list(zip(msgs, spams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input string and extract words with length >= 3\n",
    "def tokenize(text: str) -> Set[str]:\n",
    "    words: List[str] = []\n",
    "    for word in re.findall(r'[A-Za-z0-9\\']+', text):\n",
    "        if len(word) >= 3:\n",
    "            if word != \"Subject\":\n",
    "                words.append(word.lower())\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets (80/20)\n",
    "def train_test_split(messages: List[Message], pct=0.8) -> Tuple[List[Message], List[Message]]:\n",
    "    shuffle(messages)\n",
    "    num_train = int(round(len(messages) * pct, 0))\n",
    "    return messages[:num_train], messages[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self) -> None:\n",
    "        # `k` is the smoothening factor\n",
    "        self._k: int = 1\n",
    "        self._num_spam_messages: int = 0\n",
    "        self._num_ham_messages: int = 0\n",
    "        self._num_word_in_spam: Dict[int] = defaultdict(int)\n",
    "        self._num_word_in_ham: Dict[int] = defaultdict(int)\n",
    "        self._spam_words: Set[str] = set()\n",
    "        self._ham_words: Set[str] = set()\n",
    "        self._words: Set[str] = set()\n",
    "\n",
    "    # Iterate through the messages and gather the necessary numbers\n",
    "    def train(self, messages: List[Message]) -> None:\n",
    "        msg: Message\n",
    "        token: str\n",
    "        for msg in messages:\n",
    "            tokens: Set[str] = tokenize(msg[0])\n",
    "            self._words.update(tokens)\n",
    "            if msg[1] == '1':\n",
    "                self._num_spam_messages += 1\n",
    "                self._spam_words.update(tokens)\n",
    "                for token in tokens:\n",
    "                    self._num_word_in_spam[token] += 1\n",
    "            else:\n",
    "                self._num_ham_messages += 1\n",
    "                self._ham_words.update(tokens)\n",
    "                for token in tokens:\n",
    "                    self._num_word_in_ham[token] += 1                \n",
    "    \n",
    "    # Probability of a word being spam\n",
    "    def word_spam_percent(self, word: str) -> float:\n",
    "        return (self._k + self._num_word_in_spam[word]) / ((2 * self._k) + self._num_spam_messages)\n",
    "    \n",
    "    # Probability of a word being ham\n",
    "    def word_ham_percent(self, word: str) -> float:\n",
    "        return (self._k + self._num_word_in_ham[word]) / ((2 * self._k) + self._num_ham_messages)\n",
    "    \n",
    "    # Predict input message if it's spam\n",
    "    def predict(self, text: str) -> float:\n",
    "        text_words: Set[str] = tokenize(text)\n",
    "        log_p_spam: float = 0.0\n",
    "        log_p_ham: float = 0.0\n",
    "\n",
    "        for word in self._words:\n",
    "            p_spam: float = self.word_spam_percent(word)\n",
    "            p_ham: float = self.word_ham_percent(word)\n",
    "            if word in text_words:\n",
    "                log_p_spam += log(p_spam)\n",
    "                log_p_ham += log(p_ham)\n",
    "            else:\n",
    "                log_p_spam += log(1 - p_spam)\n",
    "                log_p_ham += log(1 - p_ham)\n",
    "\n",
    "        if_spam: float = exp(log_p_spam)\n",
    "        if_ham: float = exp(log_p_ham)\n",
    "        sum = if_spam + if_ham\n",
    "        if sum == 0:\n",
    "            sum = 0.1\n",
    "\n",
    "        return round(if_spam / sum, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581 1145\n"
     ]
    }
   ],
   "source": [
    "# Split train/test from the dataset\n",
    "train: List[Message]\n",
    "test: List[Message]\n",
    "\n",
    "train, test = train_test_split(messages)\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam messages in training data: 1103\n",
      "Ham messages in training data: 3478\n",
      "Most spam words: [('the', 865), ('and', 805), ('you', 787), ('your', 772), ('for', 726), ('this', 553), ('with', 522), ('our', 508), ('have', 504), ('not', 493), ('are', 490), ('from', 480), ('that', 429), ('here', 427), ('will', 398), ('all', 386), ('com', 367), ('more', 335), ('http', 321), ('now', 310)]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "nb = NaiveBayes()\n",
    "nb.train(train)\n",
    "\n",
    "print(f'Spam messages in training data: {nb._num_spam_messages}')\n",
    "print(f'Ham messages in training data: {nb._num_ham_messages}')\n",
    "print(f'Most spam words: {Counter(nb._num_word_in_spam).most_common(20)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 0.993719\n",
      "Probability: 1e-06\n",
      "Probability: 0.974627\n"
     ]
    }
   ],
   "source": [
    "# Manual test\n",
    "# spam: 1, 3\n",
    "emails = [\n",
    "    \"Hey, Jill!\\nIt's great to have you as part of our 8 Ball Pool family!\\nHere's a quick tip we hope you'll find useful:\\nPlay using Facebook login & reap rewards like...\\n5 FREE Pool Cash at time of login\\nFree Coins every hour\\nPlay on multiple devices\\nPlay with and challenge your friends\\nFree Gifts\\nHere's a little gift to help you along your 8 Ball Pool journey. Click the button below to collect now!\",\n",
    "    \"It was nice meeting you earlier. It would be great to be able to see you again.\",\n",
    "    \"Hello\\nAre you tired? Are you exhausted after a long day at work? Signup to receive a free spa at testurl.com\"\n",
    "]\n",
    "\n",
    "for email in emails:\n",
    "    print(f\"Probability: {nb.predict(email)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict messages from test set\n",
    "spam_prob: float = 0.0\n",
    "spam_count: int = 0\n",
    "spam_predict_count: int = 0\n",
    "\n",
    "for msg in test:\n",
    "    prob: float = nb.predict(msg[0])\n",
    "\n",
    "    # Count spam messages\n",
    "    if(msg[1] == \"1\"):\n",
    "        spam_count += 1\n",
    "\n",
    "    # Return the prediction of all the test message\n",
    "\n",
    "    if(prob >= 0.4):\n",
    "        spam_prob += prob\n",
    "        spam_predict_count += 1\n",
    "\n",
    "print(f\"spam count: {spam_count}\")\n",
    "print(f\"spam predicted: {spam_predict_count}\")\n",
    "print(f\"Accuracy of spam prediction: {round((spam_prob / spam_count) * 100, 3)}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
